{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hopfield Neural Network for Pattern Association "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {},
   "outputs": [],
   "source": [
    "import idx2numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign_func(x):\n",
    "    \"\"\" Sign Function\"\"\"\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    elif x < 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "def flipping_noise(image, flip_fraction):\n",
    "    \"\"\"\n",
    "    This function takes an image and a fraction representing the amount of noise\n",
    "    to add and returns a noisy image. The noise is simply flipping of pixels.\n",
    "    \"\"\"\n",
    "    # Flatten the image if it is not\n",
    "    if len(image.shape) > 1:\n",
    "        image = image.flatten()\n",
    "\n",
    "    # Generate a mask for flipping pixels\n",
    "    noise_mask = np.random.choice([False, True], len(image), p=[1-flip_fraction, flip_fraction])\n",
    "    \n",
    "    # Return a copy of the image with the pixels at the mask indices flipped\n",
    "    return np.where(noise_mask, -image, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and testing data sets\n",
    "try:\n",
    "    train_set = idx2numpy.convert_from_file('./dataset/train-images.idx3-ubyte')\n",
    "    label_set = idx2numpy.convert_from_file('./dataset/train-labels.idx1-ubyte')\n",
    "except FileNotFoundError as e:\n",
    "    print(\"One or more data files not found.\")\n",
    "    print(e)\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "threshold = 128\n",
    "pattern_size = 5\n",
    "pattern_index = 1\n",
    "is_equal = False\n",
    "iteration = 0\n",
    "train_index = []\n",
    "image_memo = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate orthogonal patterns\n",
    "# patterns = np.empty((pattern_size, 784))\n",
    "\n",
    "# # for each pattern\n",
    "# for i in range(pattern_size):\n",
    "#     # create the pattern, ensuring orthogonality\n",
    "#     pattern = np.ones(784) * (-1)\n",
    "#     pattern[i::pattern_size] = 1\n",
    "#     patterns[i] = pattern\n",
    "\n",
    "# # reshape the patterns back to 2D images\n",
    "# train_images = patterns.reshape(pattern_size, 28, 28)\n",
    "# X_train = patterns.T\n",
    "# image_memo.append(train_images[pattern_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick training images\n",
    "for digit in range(pattern_size):\n",
    "    digit_indices = np.where(label_set == digit)[0]\n",
    "    train_index.append(digit_indices[0])\n",
    "\n",
    "train_images = train_set[train_index]\n",
    "\n",
    "# Transpose the matrix so that the image indices are the third dimension\n",
    "X_train = np.transpose(train_images, (1, 2, 0))\n",
    "\n",
    "# Reshape the images (28*28) to intput data (784*1)\n",
    "X_train = np.reshape(X_train, (784, pattern_size))\n",
    "\n",
    "# Transfer greyscale images to bipolar images\n",
    "X_train = np.where(X_train > threshold, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hopfield neural network training\n",
    "weights = X_train @ X_train.T\n",
    "\n",
    "# Keep the diagonal elements to be zero\n",
    "np.fill_diagonal(weights, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hopfield neural network noise reduction\n",
    "Y_test_prev = flipping_noise(X_train[:, pattern_index], 0.1)\n",
    "\n",
    "# Vectorize the sign function and apply it to network\n",
    "sign_func_vec = np.vectorize(sign_func)\n",
    "\n",
    "while not is_equal:\n",
    "    Y_test_curr = sign_func_vec(weights @ Y_test_prev)\n",
    "\n",
    "    # Check if the output is at its stable state\n",
    "    is_equal = np.array_equal(Y_test_prev, Y_test_curr)\n",
    "    image_memo.append(Y_test_prev)\n",
    "    Y_test_prev = Y_test_curr\n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot test image and output image\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "for i in range(iteration):\n",
    "    plt.subplot(1, iteration, i+1)\n",
    "    output_image = image_memo[i].reshape(28, 28)\n",
    "    plt.imshow(output_image, cmap='gray')\n",
    "    plt.axis('off') \n",
    "\n",
    "# fig.text(0.5, 0.65, \"Noise Reduction in Image Using Hopfield Network\", fontsize=16, ha='center')  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
